{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Model Document\n",
    "## 小结\n",
    "\n",
    "* MLS：有正规方程（非迭代）、梯度下降\n",
    "* RR：有正规方程（非迭代）、梯度下降\n",
    "* KRR：有正规方程（非迭代）、梯度下降（全量）\n",
    "* Lasso：\n",
    "* LR：梯度下降、牛顿法（迭代）\n",
    "* L2LR：梯度下降、**牛顿法（迭代）**\n",
    "* KLR：梯度下降（全量）、牛顿法（迭代）\n",
    "\n",
    "其中KRR和KLR的参数$\\beta$ 都能写作特征集的线性组合有\n",
    "\n",
    "$$\\beta = \\sum_i \\alpha_i \\phi(x_i)$$\n",
    "\n",
    "但LR这边都没有正规方程，都需要迭代计算\n",
    "\n",
    "## Linear Regression\n",
    "\n",
    "代表了**经验风险最小化**\n",
    "\n",
    "目标函数为：\n",
    "\n",
    "$$\\min_{\\beta} = \\sum_{i=1}^n \\left( y_i - \\beta^T x_i\\right)^2$$\n",
    "\n",
    "矩阵形式可以写作：\n",
    "\n",
    "$$L = (y-X\\beta)^T(y-X\\beta)$$\n",
    "\n",
    "* 正规方程\n",
    "\n",
    "$$\\beta = (X^TX)^{-1}X^Ty$$\n",
    "\n",
    "* 梯度下降minibatch\n",
    "\n",
    "## Ridge Regression\n",
    "\n",
    "代表了**结构风险最小化**\n",
    "\n",
    "目标函数为\n",
    "\n",
    "$$\\min_{\\beta} = \\sum_{i=1}^n \\left( y_i - \\beta^T x_i\\right)^2 + \\lambda \\beta^T\\beta$$\n",
    "\n",
    "矩阵形式可以写作\n",
    "\n",
    "$$L = (y-X\\beta)^T(y-X\\beta) + \\lambda \\beta^T\\beta$$\n",
    "\n",
    "对$\\beta$求导有\n",
    "\n",
    "$$ \\begin{eqnarray} \n",
    "\t\\Delta &=& -2X^Ty+2X^TX\\beta + 2\\lambda \\beta \\\\ \n",
    "\t\\Delta &=& 0 \\\\\n",
    "\t\\end{eqnarray}$$\n",
    "\n",
    "可以使用\n",
    "\n",
    "* 正规方程\t\n",
    "\n",
    "$$\\beta = (X^TX+\\lambda I)^{-1}X^Ty$$\n",
    "\n",
    "* 梯度下降minibatch\n",
    "\n",
    "$$ \\begin{eqnarray} \n",
    "\t\\beta^{(r+1)} &=& \\beta^{(r)} - \\eta \\Delta \\\\\n",
    "\t &=& (1-2\\eta\\lambda) \\beta^{(r)} +2\\eta X^T(y-X\\beta)\n",
    "\t\\end{eqnarray}$$\n",
    "\n",
    "### Intercept\n",
    "通常我们不会希望截距项为0。需要单独考虑截距项\n",
    "\n",
    "* 正规方程：令\n",
    "\n",
    "$$\\lambda I = \\left[\\begin{array}{ccccc}\n",
    "\t\t0 & \\ldots & \\ldots & \\ldots & \\ldots\\\\ \n",
    "\t\t\\ldots & \\lambda & \\ldots & \\ldots & \\ldots \\\\\n",
    "\t\t\\ldots & \\ldots & \\lambda & \\ldots & \\ldots \\\\\n",
    "\t\t\\ldots & \\ldots & \\ldots & \\ldots & \\ldots \\\\\n",
    "\t\t\\ldots & \\ldots & \\ldots & \\ldots & \\lambda\n",
    "\t\\end{array}\\right]$$\n",
    "\n",
    "* 梯度下降：\n",
    "\n",
    "对更新公式：\n",
    "\n",
    "$$\\left[\\begin{array}{ccccc}\n",
    "\t\t\\beta_0 \\\\\n",
    "\t\t\\beta_1 \\\\\n",
    "\t\t\\ldots \\\\\n",
    "\t\t\\beta_{d} \n",
    "\t\\end{array}\\right] = \n",
    "\t\\left[\\begin{array}{ccccc}\n",
    "\t\t\\beta_0 + 2\\eta X^T[0,:](y-X\\beta) \\\\\n",
    "\t\t(1-2\\eta\\lambda)\\beta_1 + 2\\eta X^T[1,:](y-X\\beta) \\\\\n",
    "\t\t\\ldots \\\\\n",
    "\t\t(1-2\\eta\\lambda)\\beta_1 + 2\\eta X^T[d,:](y-X\\beta)\n",
    "\t\\end{array}\\right]$$\n",
    "\t\n",
    "* 不考虑截距项\n",
    "\n",
    "把y中心化，这样我们就不需要考虑截距项了。可以按照原来的方法来解\n",
    "\n",
    "## Kernel Ridge Regression \n",
    "\n",
    "和SVR有很强的相关关系。损失函数不同\n",
    "\n",
    "* RR损失函数为军方误差\n",
    "* **SVR损失函数为$\\max(0, |y-f(x)| - \\epsilon)$**\n",
    "\n",
    "### 求解：\n",
    "* 正规方程：\n",
    "\n",
    "正规方程变为\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "\t\\beta &=& (\\Phi^T\\Phi+\\lambda I_d)^{-1} \\Phi^T y \\\\\n",
    "\t& = & \\Phi^T(\\Phi\\Phi^T+\\lambda I_d)^{-1}y\\\\\n",
    "\t&=& \\sum_i \\alpha_i\\phi(x_i)\n",
    "\\end{eqnarray}$$\n",
    "注意：把后面这个部分看作是一个向量，使用列加和的形式\n",
    "\n",
    "有\n",
    "$$\\alpha = (K+\\lambda I)^{-1} y$$\n",
    "\n",
    "* 梯度下降\n",
    "\n",
    "把公式$\\beta = \\sum_i \\alpha_i \\phi(x_i)$带入Ridge Regression目标函数有\n",
    "\n",
    "$$\\min_{\\alpha} = \\sum_{i=1}^n \\left( y_i - \\sum_j \\alpha_j K_{i,j}\\right)^2 + \\lambda \\sum_{ij}\\alpha_i\\alpha_iK_{ij}$$\n",
    "\n",
    "对$\\alpha$求导梯度下降更新【可以用minibatch吗】\n",
    "\n",
    "### Intercept\n",
    "对于惩罚来说，和上面的是一样的，可以把对应的$\\lambda I_d$对应的intercept的$\\lambda$修改为0\n",
    "\n",
    "* 此外，需要有\n",
    "\n",
    "$$\\phi(x_i) = \\left[\\begin{array}{ccccc}\n",
    "\t\t1 \\\\\n",
    "\t\t\\phi(x_{i1})\\\\\n",
    "\t\t\\phi(x_{i2})\\\\\n",
    "\t\t\\ldots \\\\\n",
    "\t\t\\phi(x_{id})\n",
    "\t\\end{array}\\right]$$\n",
    "\n",
    "则有(假设有d个特征，1个intercept)\n",
    "\n",
    "$$K_{n\\times n} = \\Phi^T_{n \\times d}\\Phi_{n\\times d} + 1_{n \\times n}$$\n",
    "\n",
    "## Lasso Regression\n",
    "\n",
    "目标函数为\n",
    "\n",
    "$$\\min_{\\beta} = \\sum_{i=1}^n \\left( y_i - \\beta^T x_i\\right)^2 + \\lambda ||\\beta||_1$$\n",
    "\n",
    "半矩阵形式可以写作\n",
    "\n",
    "$$L = (y-X\\beta)^T(y-X\\beta) + \\lambda \\sum |\\beta|$$\n",
    "\n",
    "由于绝对值存在不可导（在$\\beta = 0$处），我们需要定义**sub-gradient**\n",
    "\n",
    "$$ -c <\\left.\\frac{\\partial \\sum |\\beta|}{\\partial \\beta}\\right|_{\\beta=0} <c$$\n",
    "\n",
    "位于左导数和右导数的中间\n",
    "\n",
    "\n",
    "### Lasso和Ridge经典比较图\n",
    "\n",
    "![lasso_ridge](./graph/lasso_ridge.png)\n",
    "\n",
    "注意图下解释\n",
    "\n",
    "## Elastic Network\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
